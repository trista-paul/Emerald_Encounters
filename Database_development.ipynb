{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJECT\n",
    "This database is to provide a tool for a particular challenge run in the videogame \"Pokemon Emerald\" where the ROM has been altered to disable experience gain. In this run, caught Pokemon will be stuck with the moves they are first caught with. This database has tables for all in-game locations and includes the available Pokemon at that location, their maximum possible level at encounter, and their four move slots in respect to their level. \n",
    "\n",
    "This data exists online, but would involve searching the move tables of every individual creature as it came up on the current in game location. It is also a practice project for creating databases from disparate data sources and for advanced web scraping.\n",
    "\n",
    "GETTING THE LEARNSET DATA\n",
    "1. scrape the names, in lowercase, of the Pokemon in Hoenn Pokedex.\n",
    "   https://pokemondb.net/pokedex/game/ruby-sapphire-emerald\n",
    "   list: names\n",
    "2. loop the pages https://pokemondb.net/pokedex/lotad/moves/3\n",
    "   with a variable iterating over names in place of lotad.\n",
    "3. For each name in names...\n",
    "   Scrape the 'Moves learnt by level up' table ('Lv.' and 'Move') from page.\n",
    "   Create a table 'name' containing 'Name', 'Level' and 'Move'.\n",
    "   \n",
    "GETTING THE LOCATION DATA\n",
    "1. scrape the locations in lowercase with no spaces.\n",
    "   https://pokemondb.net/location#tab-hoenn\n",
    "   list: locations\n",
    "2. loop the pages https://www.serebii.net/pokearth/hoenn/3rd/route102.shtml    with a variable 'loc' in place of route102.\n",
    "3. For each loc in locations...\n",
    "   Scrape the 'Pokemon Emerald' container (Pokemon name, 'Max Level') in the    'Standard Walking' container\n",
    "   create a table 'location' containing 'Name', 'MaxLv', 'Method' (which should be set equal to \"grass\"),\n",
    "   'Move1', 'Move2', 'Move3', 'Move4'.\n",
    "   \n",
    "BRINGING THE LOCATION AND LEARNSET DATA TOGETHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T04:45:30.291766Z",
     "start_time": "2019-09-01T04:45:30.265310Z"
    }
   },
   "outputs": [],
   "source": [
    "#imports including created csvs, db\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('Emerald_Encounters_beta')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "locations = pd.read_csv(\"locationlist.csv\")['0'].tolist()\n",
    "pokemon = pd.read_csv(\"pokemonlist.csv\")['0'].tolist()\n",
    "multi = pd.read_csv(\"locations_multifloor.csv\")['0'].tolist()\n",
    "multi.remove('abandonedship')\n",
    "multi.remove('skypillar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Locations List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T06:05:59.137485Z",
     "start_time": "2019-09-01T06:05:58.784435Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url_loc = 'https://pokemondb.net/location#tab-hoenn'\n",
    "response_loc = requests.get(url_loc)\n",
    "soup_loc = BeautifulSoup(response_loc.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T06:06:06.134726Z",
     "start_time": "2019-09-01T06:06:06.126400Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route 101\n",
      "Route 102\n",
      "Route 103\n",
      "Route 104\n",
      "Route 105\n",
      "Route 106\n",
      "Route 107\n",
      "Route 108\n",
      "Route 109\n",
      "Route 110\n",
      "Route 111\n",
      "Route 112\n",
      "Route 113\n",
      "Route 114\n",
      "Route 115\n",
      "\n",
      "\n",
      "Route 116\n",
      "Route 117\n",
      "Route 118\n",
      "Route 119\n",
      "Route 120\n",
      "Route 121\n",
      "Route 122\n",
      "Route 123\n",
      "Route 124\n",
      "Route 125\n",
      "Route 126\n",
      "Route 127\n",
      "Route 128\n",
      "Route 129\n",
      "Route 130\n",
      "\n",
      "\n",
      "Route 131\n",
      "Route 132\n",
      "Route 133\n",
      "Route 134\n",
      "Abandoned Ship\n",
      "Altering Cave\n",
      "Artisan Cave\n",
      "Battle Frontier\n",
      "Battle Resort\n",
      "Battle Tower\n",
      "Birth Island\n",
      "Cave of Origin\n",
      "Desert Underpass\n",
      "Dewford Town\n",
      "Ever Grande City\n",
      "\n",
      "\n",
      "Fallarbor Town\n",
      "Faraway Island\n",
      "Fiery Path\n",
      "Fortree City\n",
      "Granite Cave\n",
      "Jagged Pass\n",
      "Lavaridge Town\n",
      "Lilycove City\n",
      "Littleroot Town\n",
      "Marine Cave\n",
      "Mauville City\n",
      "Meteor Falls\n",
      "Mirage Island\n",
      "Mirage Spots\n",
      "Mirage Tower\n",
      "\n",
      "\n",
      "Mossdeep City\n",
      "Mt. Chimney\n",
      "Mt. Pyre\n",
      "New Mauville\n",
      "Oldale Town\n",
      "Pacifidlog Town\n",
      "Petalburg City\n",
      "Petalburg Woods\n",
      "Roaming Hoenn\n",
      "Rustboro City\n",
      "Rusturf Tunnel\n",
      "Safari Zone\n",
      "Scorched Slab\n",
      "Sea Mauville\n",
      "Seafloor Cavern\n",
      "\n",
      "\n",
      "Sealed Chamber\n",
      "Shoal Cave\n",
      "Sky Pillar\n",
      "Slateport City\n",
      "Sootopolis City\n",
      "Southern Island\n",
      "SS Tidal\n",
      "Team Magma/Aqua Hideout\n",
      "Terra Cave\n",
      "Trainer Hill\n",
      "Verdanturf Town\n",
      "Victory Road\n"
     ]
    }
   ],
   "source": [
    "locations = soup_loc.find(id = 'loc-hoenn').text.strip()\n",
    "print(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T06:06:20.146240Z",
     "start_time": "2019-09-01T06:06:20.142191Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "locations = locations.lower().replace(' ', '')\n",
    "locations = locations.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T06:06:22.844246Z",
     "start_time": "2019-09-01T06:06:22.838773Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['route101', 'route102', 'route103', 'route104', 'route105', 'route106', 'route107', 'route108', 'route109', 'route110', 'route111', 'route112', 'route113', 'route114', 'route115', 'route116', 'route117', 'route118', 'route119', 'route120', 'route121', 'route122', 'route123', 'route124', 'route125', 'route126', 'route127', 'route128', 'route129', 'route130', 'route131', 'route132', 'route133', 'route134', 'abandonedship', 'alteringcave', 'artisancave', 'battlefrontier', 'battleresort', 'battletower', 'birthisland', 'caveoforigin', 'desertunderpass', 'dewfordtown', 'evergrandecity', 'fallarbortown', 'farawayisland', 'fierypath', 'fortreecity', 'granitecave', 'jaggedpass', 'lavaridgetown', 'lilycovecity', 'littleroottown', 'marinecave', 'mauvillecity', 'meteorfalls', 'mirageisland', 'miragespots', 'miragetower', 'mossdeepcity', 'mt.chimney', 'mt.pyre', 'newmauville', 'oldaletown', 'pacifidlogtown', 'petalburgcity', 'petalburgwoods', 'roaminghoenn', 'rustborocity', 'rusturftunnel', 'safarizone', 'scorchedslab', 'seamauville', 'seafloorcavern', 'sealedchamber', 'shoalcave', 'skypillar', 'slateportcity', 'sootopoliscity', 'southernisland', 'sstidal', 'teammagma/aquahideout', 'terracave', 'trainerhill', 'verdanturftown', 'victoryroad']\n"
     ]
    }
   ],
   "source": [
    "locations = list(filter(None, locations))\n",
    "print(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T06:07:28.236139Z",
     "start_time": "2019-09-01T06:07:28.228970Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['route101', 'route102', 'route103', 'route104', 'route105', 'route106', 'route107', 'route108', 'route109', 'route110', 'route111', 'route112', 'route113', 'route114', 'route115', 'route116', 'route117', 'route118', 'route119', 'route120', 'route121', 'route122', 'route123', 'route124', 'route125', 'route126', 'route127', 'route128', 'route129', 'route130', 'route131', 'route132', 'route133', 'route134', 'abandonedship', 'caveoforigin', 'dewfordtown', 'evergrandecity', 'fierypath', 'granitecave', 'jaggedpass', 'lilycovecity', 'meteorfalls', 'mirageisland', 'mossdeepcity', 'mt.pyre', 'newmauville', 'pacifidlogtown', 'petalburgcity', 'petalburgwoods', 'rusturftunnel', 'safarizone', 'seafloorcavern', 'shoalcave', 'skypillar', 'slateportcity', 'sootopoliscity', 'victoryroad']\n"
     ]
    }
   ],
   "source": [
    "#delete locations with no encounters, postgame, or only contain gift pokemon\n",
    "notneeded = ['battlefrontier', 'mt.chimney', 'oldaletown',\n",
    "             'fallarbortown', 'lavaridgetown', 'mauvillecity',\n",
    "             'sstidal', 'trainerhill', 'verdanturftown',\n",
    "             'birthisland', 'artisancave', 'roaminghoenn',\n",
    "             'terracave', 'marinecave', 'alteringcave',\n",
    "             'battleresort', 'battletower', 'farawayisland',\n",
    "             'southernisland', 'teammagma/aquahideout', 'desertunderpass',\n",
    "             'miragespots', 'scorchedslab', 'seamauville', 'sealedchamber',\n",
    "             'fortreecity', 'littleroottown', 'miragetower', 'lavaridgetown',\n",
    "             'rustborocity']\n",
    "for location in notneeded:\n",
    "    while True:\n",
    "        try:\n",
    "            locations.remove(location)\n",
    "        except:\n",
    "            break\n",
    "print(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T06:07:31.958265Z",
     "start_time": "2019-09-01T06:07:31.950037Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#convert list to csv for convenience\n",
    "df = pd.DataFrame(locations)\n",
    "df.to_csv('locationlist.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pokemon Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T07:20:00.172967Z",
     "start_time": "2019-09-01T07:19:59.801562Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url_pkmn = 'https://pokemondb.net/pokedex/game/ruby-sapphire-emerald'\n",
    "response_pkmn = requests.get(url_pkmn)\n",
    "soup_pkmn = BeautifulSoup(response_pkmn.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T07:20:06.145257Z",
     "start_time": "2019-09-01T07:20:06.112430Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['treecko', 'grovyle', 'sceptile', 'torchic', 'combusken', 'blaziken', 'mudkip', 'marshtomp', 'swampert', 'poochyena', 'mightyena', 'zigzagoon', 'linoone', 'wurmple', 'silcoon', 'beautifly', 'cascoon', 'dustox', 'lotad', 'lombre', 'ludicolo', 'seedot', 'nuzleaf', 'shiftry', 'taillow', 'swellow', 'wingull', 'pelipper', 'ralts', 'kirlia', 'gardevoir', 'surskit', 'masquerain', 'shroomish', 'breloom', 'slakoth', 'vigoroth', 'slaking', 'abra', 'kadabra', 'alakazam', 'nincada', 'ninjask', 'shedinja', 'whismur', 'loudred', 'exploud', 'makuhita', 'hariyama', 'goldeen', 'seaking', 'magikarp', 'gyarados', 'azurill', 'marill', 'azumarill', 'geodude', 'graveler', 'golem', 'nosepass', 'skitty', 'delcatty', 'zubat', 'golbat', 'crobat', 'tentacool', 'tentacruel', 'sableye', 'mawile', 'aron', 'lairon', 'aggron', 'machop', 'machoke', 'machamp', 'meditite', 'medicham', 'electrike', 'manectric', 'plusle', 'minun', 'magnemite', 'magneton', 'voltorb', 'electrode', 'volbeat', 'illumise', 'oddish', 'gloom', 'vileplume', 'bellossom', 'doduo', 'dodrio', 'roselia', 'gulpin', 'swalot', 'carvanha', 'sharpedo', 'wailmer', 'wailord', 'numel', 'camerupt', 'slugma', 'magcargo', 'torkoal', 'grimer', 'muk', 'koffing', 'weezing', 'spoink', 'grumpig', 'sandshrew', 'sandslash', 'spinda', 'skarmory', 'trapinch', 'vibrava', 'flygon', 'cacnea', 'cacturne', 'swablu', 'altaria', 'zangoose', 'seviper', 'lunatone', 'solrock', 'barboach', 'whiscash', 'corphish', 'crawdaunt', 'baltoy', 'claydol', 'lileep', 'cradily', 'anorith', 'armaldo', 'igglybuff', 'jigglypuff', 'wigglytuff', 'feebas', 'milotic', 'castform', 'staryu', 'starmie', 'kecleon', 'shuppet', 'banette', 'duskull', 'dusclops', 'tropius', 'chimecho', 'absol', 'vulpix', 'ninetales', 'pichu', 'pikachu', 'raichu', 'psyduck', 'golduck', 'wynaut', 'wobbuffet', 'natu', 'xatu', 'girafarig', 'phanpy', 'donphan', 'pinsir', 'heracross', 'rhyhorn', 'rhydon', 'snorunt', 'glalie', 'spheal', 'sealeo', 'walrein', 'clamperl', 'huntail', 'gorebyss', 'relicanth', 'corsola', 'chinchou', 'lanturn', 'luvdisc', 'horsea', 'seadra', 'kingdra', 'bagon', 'shelgon', 'salamence', 'beldum', 'metang', 'metagross', 'regirock', 'regice', 'registeel', 'latias', 'latios', 'kyogre', 'groudon', 'rayquaza', 'jirachi', 'deoxys']\n"
     ]
    }
   ],
   "source": [
    "#class a.ent-name in class span.infocard-lg-data text-muted in class div.infocard\n",
    "tags_pkmn = soup_pkmn.find_all('a', attrs = {'class' : 'ent-name'})\n",
    "pokemon = []\n",
    "for pkmn in tags_pkmn:\n",
    "    pokemon.append(pkmn.text.strip().lower())\n",
    "print(pokemon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T07:23:02.253469Z",
     "start_time": "2019-09-01T07:23:02.240482Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "['poochyena', 'mightyena', 'zigzagoon', 'linoone', 'wurmple', 'silcoon', 'cascoon', 'lotad', 'lombre', 'seedot', 'nuzleaf', 'taillow', 'swellow', 'wingull', 'pelipper', 'ralts', 'shroomish', 'slakoth', 'abra', 'nincada', 'whismur', 'loudred', 'makuhita', 'hariyama', 'goldeen', 'seaking', 'magikarp', 'gyarados', 'marill', 'geodude', 'graveler', 'nosepass', 'skitty', 'zubat', 'golbat', 'tentacool', 'tentacruel', 'sableye', 'mawile', 'aron', 'lairon', 'machop', 'electrike', 'manectric', 'plusle', 'minun', 'magnemite', 'magneton', 'voltorb', 'electrode', 'volbeat', 'illumise', 'oddish', 'gloom', 'doduo', 'dodrio', 'gulpin', 'carvanha', 'sharpedo', 'wailmer', 'wailord', 'numel', 'slugma', 'torkoal', 'grimer', 'koffing', 'spoink', 'sandshrew', 'spinda', 'skarmory', 'trapinch', 'cacnea', 'swablu', 'altaria', 'seviper', 'solrock', 'barboach', 'whiscash', 'corphish', 'baltoy', 'claydol', 'jigglypuff', 'feebas', 'staryu', 'kecleon', 'shuppet', 'banette', 'duskull', 'tropius', 'chimecho', 'absol', 'vulpix', 'pikachu', 'psyduck', 'golduck', 'wynaut', 'wobbuffet', 'natu', 'xatu', 'girafarig', 'phanpy', 'pinsir', 'heracross', 'rhyhorn', 'snorunt', 'spheal', 'clamperl', 'relicanth', 'corsola', 'chinchou', 'lanturn', 'luvdisc', 'horsea', 'bagon', 'regirock', 'regice', 'registeel', 'rayquaza']\n"
     ]
    }
   ],
   "source": [
    "#delete postgame, starter or unavailable pokemon\n",
    "notneededpkmn = ['treecko', 'grovyle', 'sceptile',\n",
    "                 'torchic', 'combusken', 'blaziken',\n",
    "                 'mudkip', 'marshtomp', 'swampert',\n",
    "                 'surskit', 'masquerain', 'meditite',\n",
    "                 'medicham', 'roselia', 'zangoose',\n",
    "                 'lunatone', 'groudon', 'kyogre',\n",
    "                 'latios', 'latias', 'jirachi', 'deoxys',\n",
    "                 'beautifly', 'dustox', 'ludicolo',\n",
    "                 'shiftry', 'kirlia', 'gardevoir',\n",
    "                 'breloom', 'vigoroth', 'slaking',\n",
    "                 'ninjask', 'shedinja', 'exploud',\n",
    "                 'azurill', 'delcatty', 'aggron',\n",
    "                 'swalot', 'camerupt', 'grumpig',\n",
    "                 'vibrava', 'flygon', 'cacturne',\n",
    "                 'crawdaunt', 'cradily', 'armaldo',\n",
    "                 'milotic', 'castform', 'dusclops',\n",
    "                 'glalie', 'sealeo', 'walrein',\n",
    "                 'huntail', 'gorebyss', 'shelgon',\n",
    "                 'salamence', 'lileep', 'anorith',\n",
    "                 'beldum', 'metang', 'metagross',\n",
    "                 'raichu', 'sandslash', 'ninetales',\n",
    "                 'wigglytuff', 'vileplume', 'persian',\n",
    "                 'kadabra', 'alakazam', 'machoke',\n",
    "                 'machamp', 'golem', 'muk', 'weezing',\n",
    "                 'rhydon', 'seadra', 'starmie', 'crobat',\n",
    "                 'pichu', 'igglybuff', 'bellossom',\n",
    "                 'azumarill', 'magcargo', 'kingdra',\n",
    "                 'donphan']\n",
    "\n",
    "pokemon = pokemon\n",
    "for pkmn in notneededpkmn:\n",
    "    while True:\n",
    "        try:\n",
    "            pokemon.remove(pkmn)\n",
    "        except:\n",
    "            break\n",
    "print(len(pokemon))\n",
    "print(pokemon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T07:23:13.303423Z",
     "start_time": "2019-09-01T07:23:13.296636Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#convert to csv\n",
    "df = pd.DataFrame(pokemon)\n",
    "df.to_csv('pokemonlist.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T04:48:10.076896Z",
     "start_time": "2019-08-29T04:48:09.914883Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#table for connecting tables that use id to tables that use name\n",
    "\n",
    "cursor.execute('CREATE TABLE POKEMON \\\n",
    "                  (PKID INT NOT NULL, \\\n",
    "                   NAME TEXT NOT NULL);')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T04:48:13.573765Z",
     "start_time": "2019-08-29T04:48:13.367176Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#ids are 0-116 in order of list\n",
    "for n in range(len(pokemon)):\n",
    "     cursor.execute(\"INSERT INTO POKEMON (PKID, NAME) \\\n",
    "                     VALUES(\" +str(n) +\",'\" +str(pokemon[n]) +\"');\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T04:48:05.296240Z",
     "start_time": "2019-08-29T04:48:05.089571Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#drop table if needed for debug\n",
    "cursor.execute(\"DROP TABLE POKEMON\");\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:34:19.497270Z",
     "start_time": "2019-08-30T08:34:19.489620Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aipom', 'teddiursa', 'ledyba', 'sunkern', 'hoothoot', 'pineco', 'houndour', 'miltank', 'shuckle', 'mareep', 'spinarak', 'gligar', 'snubbull', 'stantler', 'wooper', 'quagsire', 'remoraid', 'octillery', 'rayquaza']\n"
     ]
    }
   ],
   "source": [
    "#filter out nat dex pokemon that happened to be scraped in the encounter tables\n",
    "cursor.execute(\"SELECT DISTINCT NAME FROM WILDS;\")\n",
    "wilds_pkmn = cursor.fetchall()\n",
    "wilds_list = []\n",
    "for tuple_list in wilds_pkmn:\n",
    "    wilds_list.append(tuple_list[0])\n",
    "\n",
    "for mon in pokemon:\n",
    "    if mon in wilds_list:\n",
    "        wilds_list.remove(mon)\n",
    "        \n",
    "print(wilds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:40:49.170682Z",
     "start_time": "2019-08-30T08:40:48.900917Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for mon in wilds_list:\n",
    "    cursor.execute(\"DELETE FROM WILDS WHERE NAME == '\"+str(mon)+\"';\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Learnset Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T03:11:10.893387Z",
     "start_time": "2019-08-29T03:11:10.647262Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astonish', 'growl', 'absorb', 'nature power', 'mist', 'rain dance', 'mega drain']\n",
      "[1, 3, 7, 13, 21, 31, 43]\n"
     ]
    }
   ],
   "source": [
    "#one learnset scrape\n",
    "\n",
    "#make soup given pkmn name\n",
    "pkmn = 'lotad'\n",
    "url = 'https://pokemondb.net/pokedex/' + str(pkmn) + '/moves/3'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "#name of moves\n",
    "#the soup needs to find all a tags of 'ent-name' class\n",
    "#WITHIN the first instance of tbody tag\n",
    "table = soup.find('tbody')\n",
    "tags_moves = table.find_all('a', attrs = {'class' : 'ent-name'})\n",
    "moves = []\n",
    "for move in tags_moves:\n",
    "    moves.append(move.text.strip().lower())\n",
    "print(moves)\n",
    "\n",
    "#we also need the cooresponding levels\n",
    "#first instance of td tag of class 'cell-num', for all tr tags\n",
    "tags_cells = table.find_all('tr')\n",
    "tags_levels = []\n",
    "for cell in tags_cells:\n",
    "    level = cell.find('td', attrs = {'class' : 'cell-num'})\n",
    "    tags_levels.append(level)\n",
    "levels = []\n",
    "for level in tags_levels:\n",
    "    levels.append(int(level.text.strip()))\n",
    "print(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T03:13:12.908014Z",
     "start_time": "2019-08-29T03:13:12.892766Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#must be true to continue\n",
    "len(moves) == len(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T03:16:49.152105Z",
     "start_time": "2019-08-29T03:16:48.790934Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#conversion of moves and levels into a sqlite table\n",
    "\n",
    "cursor.execute('CREATE TABLE pkmn_'+ str(pkmn) +' \\\n",
    "                  (MOVE TEXT NOT NULL, \\\n",
    "                   LV INT NOT NULL);')\n",
    "                   \n",
    "for i in range(len(moves)):\n",
    "    cursor.execute(\"INSERT INTO pkmn_\"+ str(pkmn) +\" (MOVE, LV) \\\n",
    "                    VALUES('\"+str(moves[i]) +\"',\" + str(levels[i]) +\")\")\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T03:16:55.184872Z",
     "start_time": "2019-08-29T03:16:55.177145Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astonish\n",
      "1\n",
      "growl\n",
      "3\n",
      "absorb\n",
      "7\n",
      "nature power\n",
      "13\n",
      "mist\n",
      "21\n",
      "rain dance\n",
      "31\n",
      "mega drain\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "#verification that the table is correct\n",
    "\n",
    "for row in cursor.execute(\"SELECT MOVE, LV FROM pkmn_lotad\"):\n",
    "    print(row[0])\n",
    "    print(row[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T03:17:08.560338Z",
     "start_time": "2019-08-29T03:17:08.411299Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#drop pkmn_lotad so it doesn't interfere with the loop\n",
    "cursor.execute('DROP TABLE pkmn_lotad');\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T03:34:42.081298Z",
     "start_time": "2019-08-29T03:33:03.373166Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#and now the loop of all the above\n",
    "\n",
    "for pkmn in pokemon:\n",
    "\n",
    "    #soup\n",
    "    url = 'https://pokemondb.net/pokedex/' + str(pkmn) + '/moves/3'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    #list of moves\n",
    "    table = soup.find('tbody')\n",
    "    tags_moves = table.find_all('a', attrs = {'class' : 'ent-name'})\n",
    "    moves = []\n",
    "    for move in tags_moves:\n",
    "        moves.append(move.text.strip().lower())\n",
    "    \n",
    "    #list of move levels\n",
    "    tags_cells = table.find_all('tr')\n",
    "    tags_levels = []\n",
    "    for cell in tags_cells:\n",
    "        level = cell.find('td', attrs = {'class' : 'cell-num'})\n",
    "        tags_levels.append(level)\n",
    "    levels = []\n",
    "    for level in tags_levels:\n",
    "        levels.append(int(level.text.strip()))\n",
    "    \n",
    "    #create and populate table\n",
    "    cursor.execute('CREATE TABLE pkmn_'+ str(pkmn) +' \\\n",
    "                  (MOVE TEXT NOT NULL, \\\n",
    "                   LV INT NOT NULL);')               \n",
    "    for i in range(len(moves)):\n",
    "        cursor.execute(\"INSERT INTO pkmn_\"+ str(pkmn) +\" (MOVE, LV) \\\n",
    "                        VALUES('\"+str(moves[i]) +\"',\" + str(levels[i]) +\")\")\n",
    "    conn.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T03:27:35.440292Z",
     "start_time": "2019-08-29T03:27:34.063542Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: pkmn_lotad",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-eb8b7860179d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#loop for resetting db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpkmn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpokemon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DROP TABLE pkmn_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkmn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: pkmn_lotad"
     ]
    }
   ],
   "source": [
    "#loop for resetting db if needed\n",
    "for pkmn in pokemon:\n",
    "    cursor.execute('DROP TABLE pkmn_'+str(pkmn));\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T04:08:35.353251Z",
     "start_time": "2019-08-29T04:08:35.098824Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#in which I realize all of the above was idiotic when I could be populating one table with one-to-many ids\n",
    "#this new table has a connection to the db 'Emerald_Encounters'\n",
    "\n",
    "cursor.execute('CREATE TABLE LEARNSETS \\\n",
    "                  (PKID INT NOT NULL, \\\n",
    "                   MOVE TEXT NOT NULL, \\\n",
    "                   LV INT NOT NULL);')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T04:20:48.412001Z",
     "start_time": "2019-08-29T04:19:48.380583Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for n in range(len(pokemon)):\n",
    "\n",
    "    #soup\n",
    "    url = 'https://pokemondb.net/pokedex/' + str(pokemon[n]) + '/moves/3'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    #list of moves\n",
    "    table = soup.find('tbody')\n",
    "    tags_moves = table.find_all('a', attrs = {'class' : 'ent-name'})\n",
    "    moves = []\n",
    "    for move in tags_moves:\n",
    "        moves.append(move.text.strip().lower())\n",
    "    \n",
    "    #list of move levels\n",
    "    tags_cells = table.find_all('tr')\n",
    "    tags_levels = []\n",
    "    for cell in tags_cells:\n",
    "        level = cell.find('td', attrs = {'class' : 'cell-num'})\n",
    "        tags_levels.append(level)\n",
    "    levels = []\n",
    "    for level in tags_levels:\n",
    "        levels.append(int(level.text.strip()))\n",
    "    \n",
    "    #populate table              \n",
    "    for i in range(len(moves)):\n",
    "        cursor.execute(\"INSERT INTO LEARNSETS (PKID, MOVE, LV) \\\n",
    "                        VALUES(\"+str(n)+\",'\"+str(moves[i]) +\"',\" \\\n",
    "                                + str(levels[i]) +\")\")\n",
    "    conn.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Encounter Table (LOCATION, NAME, LV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T07:43:49.024393Z",
     "start_time": "2019-08-29T07:43:47.775114Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wurmple', 'poochyena', 'lotad', 'zigzagoon', 'ralts', 'seedot', 'marill', 'goldeen', 'magikarp', 'goldeen', 'magikarp', 'goldeen', 'corphish', 'corphish']\n",
      "[3, 4, 3, 4, 3, 4, 3, 4, 4, 4, 3, 3, 5, 35, 20, 30, 5, 10, 5, 10, 10, 30, 10, 30, 10, 30, 20, 45]\n",
      "[4, 4, 4, 4, 4, 3, 35, 30, 10, 10, 30, 30, 30, 45]\n"
     ]
    }
   ],
   "source": [
    "#one location scrape\n",
    "\n",
    "#soup\n",
    "loc = 'route102'\n",
    "url =  'https://www.serebii.net/pokearth/hoenn/3rd/' + str(loc) + '.shtml'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "#name of pokemon\n",
    "#tag table class 'dextable' --> tag td class 'name'\n",
    "#unfortunately, by finding all dextable instances, encounters are not organized by method\n",
    "#the site formatting didn't allow for automated method classification\n",
    "\n",
    "tables = soup.find_all('table', attrs = {'class' : 'dextable'})\n",
    "encounters = []\n",
    "for table in tables:\n",
    "    tags_encounters = table.find_all('td', attrs = {'class' : 'name'})\n",
    "    for name in tags_encounters:\n",
    "        encounters.append(name.text.strip().lower())\n",
    "print(encounters)\n",
    "\n",
    "#max level\n",
    "#tag table class 'dextable' --> tag td class 'level'\n",
    "encounter_levels = []\n",
    "for table in tables:\n",
    "    tags_levels = table.find_all('td', attrs = {'class' : 'level'})\n",
    "    for level in tags_levels:\n",
    "        encounter_levels.append(int(level.text.strip()))\n",
    "print(encounter_levels)\n",
    "\n",
    "#there is no distinction between max and min level\n",
    "#will have to remove even number tags (as count starts at 0)\n",
    "max_levels = []\n",
    "for i in range(len(encounter_levels)):\n",
    "    if encounter_levels[i] == 0:\n",
    "        continue\n",
    "    if i % 2 != 0:\n",
    "        max_levels.append(encounter_levels[i])\n",
    "    else:\n",
    "        continue\n",
    "print(max_levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T06:01:27.422955Z",
     "start_time": "2019-08-29T06:01:27.416047Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max_levels) == len(encounters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T06:57:17.971118Z",
     "start_time": "2019-08-30T06:57:17.829251Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('CREATE TABLE WILDS \\\n",
    "                  (LOCATION TEXT NOT NULL, \\\n",
    "                   ENCOUNTER_ID INT NOT NULL, \\\n",
    "                   NAME TEXT NOT NULL, \\\n",
    "                   LV INT NOT NULL, \\\n",
    "                   MOVE1 TEXT, \\\n",
    "                   MOVE2 TEXT, \\\n",
    "                   MOVE3 TEXT, \\\n",
    "                   MOVE4 TEXT);')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T06:57:11.025253Z",
     "start_time": "2019-08-30T06:57:10.890676Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#drop wilds table if needed\n",
    "cursor.execute(\"DROP TABLE WILDS\");\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T06:59:30.118883Z",
     "start_time": "2019-08-30T06:57:27.891912Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(len(locations)):\n",
    "    url =  'https://www.serebii.net/pokearth/hoenn/3rd/' + str(locations[n]) + '.shtml'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all('table', attrs = {'class' : 'dextable'})\n",
    "    encounters = []\n",
    "    for table in tables:\n",
    "        tags_encounters = table.find_all('td', attrs = {'class' : 'name'})\n",
    "        for name in tags_encounters:\n",
    "            encounters.append(name.text.strip().lower())\n",
    "\n",
    "    encounter_levels = []\n",
    "    for table in tables:\n",
    "        tags_levels = table.find_all('td', attrs = {'class' : 'level'})\n",
    "        for level in tags_levels:\n",
    "            encounter_levels.append(int(level.text.strip()))\n",
    "\n",
    "    max_levels = []\n",
    "    for i in range(len(encounter_levels)):\n",
    "        if encounter_levels[i] == 0:\n",
    "            continue\n",
    "        if i % 2 != 0:\n",
    "            max_levels.append(encounter_levels[i])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    #populating table\n",
    "    for x in range(len(encounters)):\n",
    "        cursor.execute(\"INSERT INTO WILDS (LOCATION, ENCOUNTER_ID, NAME, LV) \\\n",
    "                        VALUES('\"+str(locations[n])+\"',\" \\\n",
    "                                 +str(x)+\",'\" \\\n",
    "                                 +str(encounters[x])+\"',\" \\\n",
    "                                 +str(max_levels[x])+\")\");\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T07:15:26.478108Z",
     "start_time": "2019-08-30T07:15:20.910770Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#manually restoring the data that couldn't be automated\n",
    "          \n",
    "route101 = [['route101', 'wurmple', 3],\n",
    "            ['route101', 'poochyena', 3],\n",
    "            ['route101', 'zigzagoon', 3]]\n",
    "\n",
    "route110 = [['route110', 'electrike', 13],\n",
    "            ['route110', 'poochyena', 12],\n",
    "            ['route110', 'minun', 13],\n",
    "            ['route110', 'gulpin', 13],\n",
    "            ['route110', 'oddish', 13],\n",
    "            ['route110', 'wingull', 12],\n",
    "            ['route110', 'plusle', 13],\n",
    "            ['route110', 'tentacool', 35],\n",
    "            ['route110', 'wingull', 30],\n",
    "            ['route110', 'pelipper', 30],\n",
    "            ['route110', 'magikarp', 10],\n",
    "            ['route110', 'tentacool', 10],\n",
    "            ['route110', 'magikarp', 30],\n",
    "            ['route110', 'tentacool', 30],\n",
    "            ['route110', 'wailmer', 30],\n",
    "            ['route110', 'wailmer', 45]]\n",
    "            \n",
    "route119 = [['route119', 'oddish', 27],\n",
    "            ['route119', 'zigzagoon', 27],\n",
    "            ['route119', 'linoone', 27],\n",
    "            ['route119', 'tropius', 27],\n",
    "            ['route119', 'kecleon', 25],\n",
    "            ['route119', 'tentacool', 35],\n",
    "            ['route119', 'wingull', 30],\n",
    "            ['route119', 'pelipper', 30],\n",
    "            ['route119', 'magikarp', 10],\n",
    "            ['route119', 'goldeen', 10],\n",
    "            ['route119', 'magikarp', 30],\n",
    "            ['route119', 'tentacool', 30],\n",
    "            ['route119', 'carvanha', 30],\n",
    "            ['route119', 'feebas', 35],\n",
    "            ['route119', 'carvanha', 45]]\n",
    "            \n",
    "miragetower = [['miragetower', 'sandshrew', 24],\n",
    "               ['miragetower', 'trapinch', 24]]\n",
    "               \n",
    "mossdeepcity = [['mossdeepcity', 'tentacool', 35],\n",
    "                ['mossdeepcity', 'wingull', 30],\n",
    "                ['mossdeepcity', 'pelipper', 30],\n",
    "                ['mossdeepcity', 'magikarp', 10],\n",
    "                ['mossdeepcity', 'tentacool', 10],\n",
    "                ['mossdeepcity', 'magikarp', 30],\n",
    "                ['mossdeepcity', 'tentacool', 30],\n",
    "                ['mossdeepcity', 'wailmer', 30],\n",
    "                ['mossdeepcity', 'wailmer', 45],\n",
    "                ['mossdeepcity', 'sharpedo', 35]]\n",
    "\n",
    "errors = [route101, route110, route119, miragetower, mossdeepcity]\n",
    "\n",
    "for location in errors:\n",
    "    for x in range(len(location)):\n",
    "        cursor.execute(\"INSERT INTO WILDS (LOCATION, ENCOUNTER_ID, NAME, LV) \\\n",
    "                        VALUES('\"+str(location[x][0])+\"',\" \\\n",
    "                                 +str(x)+\",'\" \\\n",
    "                                 +str(location[x][1])+\"',\" \\\n",
    "                                 +str(location[x][2])+\")\");\n",
    "        conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T07:17:18.242293Z",
     "start_time": "2019-08-30T07:17:18.232239Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#adding the used locations back in list\n",
    "errors = ['route101', 'route110', 'route119', 'miragetower', 'mossdeepcity']\n",
    "for loc in errors:\n",
    "    locations.append(loc)\n",
    "df = pd.DataFrame(locations)\n",
    "df.to_csv('locationlist.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Encounter Table (MOVE1 - MOVE4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T07:17:31.200210Z",
     "start_time": "2019-08-30T07:17:31.194412Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T07:22:26.844930Z",
     "start_time": "2019-08-30T07:22:26.824049Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wrap', 'bubble beam', 'acid', 'constrict']\n",
      "wrap\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fa48859cdc0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieving the moveset of one pokemon\n",
    "#intended result : ['wrap', 'bubble beam', 'acid', 'constrict']\n",
    "pkmn = 'tentacool'\n",
    "LV = 35\n",
    "LOCATION = 'mossdeepcity'\n",
    "ENCOUNTER_ID = 0\n",
    "\n",
    "cursor.execute(\"SELECT PKID FROM POKEMON \\\n",
    "                WHERE NAME =='\"+str(pkmn)+\"';\")\n",
    "PKID = cursor.fetchall()[0][0]\n",
    "cursor.execute(\"SELECT MOVE FROM LEARNSETS \\\n",
    "                        WHERE PKID == \"+str(PKID)+\" \\\n",
    "                        AND LV <= \"+str(LV)+\" \\\n",
    "                        ORDER BY LV DESC LIMIT 4;\")\n",
    "moveset = cursor.fetchall()\n",
    "#converting moveset to a list\n",
    "moveset_as_list = []\n",
    "for tuple_list in moveset:\n",
    "    moveset_as_list.append(tuple_list[0])\n",
    "    \n",
    "print(moveset_as_list)\n",
    "\n",
    "#moveset_as_list = iterated value in moveset_list\n",
    "print(moveset_as_list[0])\n",
    "\n",
    "#updating the database with moveset\n",
    "cursor.execute(\"UPDATE WILDS \\\n",
    "                SET MOVE1 = '\"+str(moveset_as_list[0])+\"', \\\n",
    "                    MOVE2 = '\"+str(moveset_as_list[1])+\"', \\\n",
    "                    MOVE3 = '\"+str(moveset_as_list[2])+\"', \\\n",
    "                    MOVE4 = '\"+str(moveset_as_list[3])+\"' \\\n",
    "                WHERE LOCATION == '\"+str(LOCATION)+\"' \\\n",
    "                      AND ENCOUNTER_ID == \"+str(ENCOUNTER_ID)+\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T07:39:50.183808Z",
     "start_time": "2019-08-30T07:39:50.173681Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mossdeepcity 0 tentacool 35\n",
      "mossdeepcity 1 wingull 30\n",
      "mossdeepcity 2 pelipper 30\n",
      "mossdeepcity 3 magikarp 10\n",
      "mossdeepcity 4 tentacool 10\n",
      "mossdeepcity 5 magikarp 30\n",
      "mossdeepcity 6 tentacool 30\n",
      "mossdeepcity 7 wailmer 30\n",
      "mossdeepcity 8 wailmer 45\n",
      "mossdeepcity 9 sharpedo 35\n"
     ]
    }
   ],
   "source": [
    "#how encounters are iterated\n",
    "cursor.execute(\"SELECT * FROM WILDS WHERE LOCATION == 'mossdeepcity';\")\n",
    "encounters = cursor.fetchall()\n",
    "\n",
    "for mon in encounters:\n",
    "    LOCATION = mon[0]\n",
    "    ENCOUNTER_ID = mon[1]\n",
    "    NAME = mon[2]\n",
    "    LV = mon[3]\n",
    "    print(LOCATION, ENCOUNTER_ID, NAME, LV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:02:02.020656Z",
     "start_time": "2019-08-30T08:02:01.110280Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['wrap', 'bubble beam', 'acid', 'constrict'], ['mist', 'wing attack', 'supersonic', 'growl'], ['protect', 'mist', 'wing attack', 'supersonic'], ['splash'], ['supersonic', 'poison sting'], ['flail', 'tackle', 'splash'], ['wrap', 'bubble beam', 'acid', 'constrict'], ['water pulse', 'astonish', 'whirlpool', 'rollout'], ['water spout', 'rest', 'mist', 'water pulse'], ['slash', 'screech', 'crunch', 'scary face']]\n",
      "10\n",
      "[('mossdeepcity', 0, 'tentacool', 35, 'wrap', 'bubble beam', 'acid', 'constrict'), ('mossdeepcity', 1, 'wingull', 30, 'mist', 'wing attack', 'supersonic', 'growl'), ('mossdeepcity', 2, 'pelipper', 30, 'protect', 'mist', 'wing attack', 'supersonic'), ('mossdeepcity', 3, 'magikarp', 10, 'splash', None, None, None), ('mossdeepcity', 4, 'tentacool', 10, 'supersonic', 'poison sting', None, None), ('mossdeepcity', 5, 'magikarp', 30, 'flail', 'tackle', 'splash', None), ('mossdeepcity', 6, 'tentacool', 30, 'wrap', 'bubble beam', 'acid', 'constrict'), ('mossdeepcity', 7, 'wailmer', 30, 'water pulse', 'astonish', 'whirlpool', 'rollout'), ('mossdeepcity', 8, 'wailmer', 45, 'water spout', 'rest', 'mist', 'water pulse'), ('mossdeepcity', 9, 'sharpedo', 35, 'slash', 'screech', 'crunch', 'scary face')]\n"
     ]
    }
   ],
   "source": [
    "#retrieving moveset data for the pokemon of one location\n",
    "#intended len of moveset_list == 10\n",
    "\n",
    "cursor.execute(\"SELECT * FROM WILDS WHERE LOCATION == 'mossdeepcity';\")\n",
    "encounters = cursor.fetchall()\n",
    "\n",
    "#get the moveset for each encounter\n",
    "for mon in encounters:\n",
    "    \n",
    "    LOCATION = mon[0]\n",
    "    ENCOUNTER_ID = mon[1]\n",
    "    NAME = mon[2]\n",
    "    LV = mon[3]\n",
    "    \n",
    "    cursor.execute(\"SELECT PKID FROM POKEMON \\\n",
    "                    WHERE NAME =='\"+str(NAME)+\"';\")\n",
    "    PKID = cursor.fetchall()[0][0]\n",
    "    cursor.execute(\"SELECT MOVE FROM LEARNSETS \\\n",
    "                            WHERE PKID == \"+str(PKID)+\" \\\n",
    "                            AND LV <= \"+str(LV)+\" \\\n",
    "                            ORDER BY LV DESC LIMIT 4;\")\n",
    "    moveset = cursor.fetchall()\n",
    "    \n",
    "    #converting moveset to a list\n",
    "    moveset_as_list = []\n",
    "    for tuple_list in moveset:\n",
    "        moveset_as_list.append(tuple_list[0])\n",
    "        \n",
    "    #add moveset to wilds\n",
    "    if len(moveset_as_list) == 4:\n",
    "        cursor.execute(\"UPDATE WILDS \\\n",
    "                        SET MOVE1 = '\"+str(moveset_as_list[0])+\"', \\\n",
    "                            MOVE2 = '\"+str(moveset_as_list[1])+\"', \\\n",
    "                            MOVE3 = '\"+str(moveset_as_list[2])+\"', \\\n",
    "                            MOVE4 = '\"+str(moveset_as_list[3])+\"' \\\n",
    "                        WHERE LOCATION == '\"+str(LOCATION)+\"' \\\n",
    "                              AND ENCOUNTER_ID == \"+str(ENCOUNTER_ID)+\";\")\n",
    "        conn.commit()\n",
    "    elif len(moveset_as_list) == 3:\n",
    "        cursor.execute(\"UPDATE WILDS \\\n",
    "                        SET MOVE1 = '\"+str(moveset_as_list[0])+\"', \\\n",
    "                            MOVE2 = '\"+str(moveset_as_list[1])+\"', \\\n",
    "                            MOVE3 = '\"+str(moveset_as_list[2])+\"' \\\n",
    "                        WHERE LOCATION == '\"+str(LOCATION)+\"' \\\n",
    "                              AND ENCOUNTER_ID == \"+str(ENCOUNTER_ID)+\";\")\n",
    "        conn.commit()\n",
    "    elif len(moveset_as_list) == 2:\n",
    "        cursor.execute(\"UPDATE WILDS \\\n",
    "                        SET MOVE1 = '\"+str(moveset_as_list[0])+\"', \\\n",
    "                            MOVE2 = '\"+str(moveset_as_list[1])+\"' \\\n",
    "                        WHERE LOCATION == '\"+str(LOCATION)+\"' \\\n",
    "                              AND ENCOUNTER_ID == \"+str(ENCOUNTER_ID)+\";\")\n",
    "        conn.commit()\n",
    "    else:\n",
    "        cursor.execute(\"UPDATE WILDS \\\n",
    "                        SET MOVE1 = '\"+str(moveset_as_list[0])+\"' \\\n",
    "                        WHERE LOCATION == '\"+str(LOCATION)+\"' \\\n",
    "                              AND ENCOUNTER_ID == \"+str(ENCOUNTER_ID)+\";\")\n",
    "        conn.commit()\n",
    "    \n",
    "\n",
    "print(moveset_list)\n",
    "print(len(moveset_list))\n",
    "cursor.execute(\"SELECT * FROM WILDS WHERE LOCATION == 'mossdeepcity';\")\n",
    "print(cursor.fetchall())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:42:10.222487Z",
     "start_time": "2019-08-30T08:41:47.764099Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#the final loop - all locations\n",
    "\n",
    "for loc in locations:\n",
    "    \n",
    "    #get encounter table for location\n",
    "    cursor.execute(\"SELECT * FROM WILDS WHERE LOCATION == '\"+str(loc)+\"';\")\n",
    "    encounters = cursor.fetchall()\n",
    "\n",
    "    for mon in encounters:\n",
    "        \n",
    "        #get moveset for a given encounter\n",
    "        LOCATION = mon[0]\n",
    "        ENCOUNTER_ID = mon[1]\n",
    "        NAME = mon[2]\n",
    "        LV = mon[3]\n",
    "\n",
    "        cursor.execute(\"SELECT PKID FROM POKEMON \\\n",
    "                        WHERE NAME =='\"+str(NAME)+\"';\")\n",
    "        PKID = cursor.fetchall()[0][0]\n",
    "        cursor.execute(\"SELECT MOVE FROM LEARNSETS \\\n",
    "                                WHERE PKID == \"+str(PKID)+\" \\\n",
    "                                AND LV <= \"+str(LV)+\" \\\n",
    "                                ORDER BY LV DESC LIMIT 4;\")\n",
    "        moveset = cursor.fetchall()\n",
    "\n",
    "        #converting moveset to a list\n",
    "        moveset_as_list = []\n",
    "        for tuple_list in moveset:\n",
    "            moveset_as_list.append(tuple_list[0])\n",
    "\n",
    "        #add moveset to wilds\n",
    "        if len(moveset_as_list) == 4:\n",
    "            cursor.execute(\"UPDATE WILDS \\\n",
    "                            SET MOVE1 = '\"+str(moveset_as_list[0])+\"', \\\n",
    "                                MOVE2 = '\"+str(moveset_as_list[1])+\"', \\\n",
    "                                MOVE3 = '\"+str(moveset_as_list[2])+\"', \\\n",
    "                                MOVE4 = '\"+str(moveset_as_list[3])+\"' \\\n",
    "                            WHERE LOCATION == '\"+str(LOCATION)+\"' \\\n",
    "                                  AND ENCOUNTER_ID == \"+str(ENCOUNTER_ID)+\";\")\n",
    "            conn.commit()\n",
    "        elif len(moveset_as_list) == 3:\n",
    "            cursor.execute(\"UPDATE WILDS \\\n",
    "                            SET MOVE1 = '\"+str(moveset_as_list[0])+\"', \\\n",
    "                                MOVE2 = '\"+str(moveset_as_list[1])+\"', \\\n",
    "                                MOVE3 = '\"+str(moveset_as_list[2])+\"' \\\n",
    "                            WHERE LOCATION == '\"+str(LOCATION)+\"' \\\n",
    "                                  AND ENCOUNTER_ID == \"+str(ENCOUNTER_ID)+\";\")\n",
    "            conn.commit()\n",
    "        elif len(moveset_as_list) == 2:\n",
    "            cursor.execute(\"UPDATE WILDS \\\n",
    "                            SET MOVE1 = '\"+str(moveset_as_list[0])+\"', \\\n",
    "                                MOVE2 = '\"+str(moveset_as_list[1])+\"' \\\n",
    "                            WHERE LOCATION == '\"+str(LOCATION)+\"' \\\n",
    "                                  AND ENCOUNTER_ID == \"+str(ENCOUNTER_ID)+\";\")\n",
    "            conn.commit()\n",
    "        else:\n",
    "            cursor.execute(\"UPDATE WILDS \\\n",
    "                            SET MOVE1 = '\"+str(moveset_as_list[0])+\"' \\\n",
    "                            WHERE LOCATION == '\"+str(LOCATION)+\"' \\\n",
    "                                  AND ENCOUNTER_ID == \"+str(ENCOUNTER_ID)+\";\")\n",
    "            conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Adding abilities to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:40:14.804663Z",
     "start_time": "2019-08-30T10:40:09.479131Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.smogon.com/dex/rs/pokemon/abra/'\n",
    "\n",
    "#<ul class=\"AbilityList\" data-reactid=\".0.1.1.4.1.0:1.1.0.0.1.1.0\"><li data-reactid=\".0.1.1.4.1.0:1.1.0.0.1.1.0.$Inner Focus\"><a href=\"/dex/rs/abilities/inner-focus/\" data-reactid=\".0.1.1.4.1.0:1.1.0.0.1.1.0.$Inner Focus.0\">Inner Focus</a></li><li data-reactid=\".0.1.1.4.1.0:1.1.0.0.1.1.0.$Synchronize\"><a href=\"/dex/rs/abilities/synchronize/\" data-reactid=\".0.1.1.4.1.0:1.1.0.0.1.1.0.$Synchronize.0\">Synchronize</a></li></ul>\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "tags = soup.find('AbilityList')\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Rehaul Wilds - Adding Encounter Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T22:36:28.527424Z",
     "start_time": "2019-08-31T22:36:28.362222Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('CREATE TABLE WILDS \\\n",
    "                  (LOCATION TEXT NOT NULL, \\\n",
    "                   ENCOUNTER_ID INT NOT NULL, \\\n",
    "                   METHOD TEXT NOT NULL, \\\n",
    "                   NAME TEXT NOT NULL, \\\n",
    "                   ABILITY TEXT, \\\n",
    "                   LV INT NOT NULL, \\\n",
    "                   MOVE1 TEXT, \\\n",
    "                   MOVE2 TEXT, \\\n",
    "                   MOVE3 TEXT, \\\n",
    "                   MOVE4 TEXT);')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T22:36:23.694555Z",
     "start_time": "2019-08-31T22:36:23.456148Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cursor.execute(\"DROP TABLE WILDS\");\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T22:17:06.506655Z",
     "start_time": "2019-08-31T22:15:21.182996Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route111\n",
      "route119\n",
      "abandonedship\n",
      "caveoforigin\n",
      "dewfordtown\n",
      "evergrandecity\n",
      "granitecave\n",
      "meteorfalls\n",
      "mossdeepcity\n",
      "mt.pyre\n",
      "newmauville\n",
      "petalburgcity\n",
      "safarizone\n",
      "seafloorcavern\n",
      "shoalcave\n",
      "skypillar\n",
      "slateportcity\n",
      "sootopoliscity\n",
      "victoryroad\n"
     ]
    }
   ],
   "source": [
    "multi = []\n",
    "for l in range(len(locations)):\n",
    "    url =  'https://www.serebii.net/pokearth/hoenn/3rd/' + str(locations[l]) + '.shtml'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    method_list = ['grass', 'surf', 'fish', 'rocksmash', 'interact', 'gift']\n",
    "    anchortab = soup.find_all('table', attrs={'class':'anctab'})\n",
    "    anchortab = anchortab[1]\n",
    "    anchors = anchortab.find_all('td', attrs = {'class' : method_list})\n",
    "    method = []\n",
    "    for anchor in anchors:\n",
    "        method.append(anchor.text.strip())\n",
    "    \n",
    "    if 'Area Anchors' in method:\n",
    "        print(locations[l])\n",
    "        multi.append(locations[l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T22:21:54.231672Z",
     "start_time": "2019-08-31T22:21:54.222005Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#desynced the methods by having multiple areas\n",
    "for loc in multi:\n",
    "    locations.remove(loc)\n",
    "locations.remove(\"route120\") #is failing to retrieve 'interaction' anchor\n",
    "\n",
    "df = pd.DataFrame(locations)\n",
    "df.to_csv('locations_singlefloor.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T22:23:24.490024Z",
     "start_time": "2019-08-31T22:23:24.479215Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(multi)\n",
    "df.to_csv('locations_multifloor.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T06:22:42.151087Z",
     "start_time": "2019-09-01T06:22:22.572135Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='www.serebii.net', port=443): Max retries exceeded with url: /pokearth/hoenn/3rd/route120.shtml (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb556626ef0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 160\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    602\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 169\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x7fb556626ef0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    640\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 641\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    642\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.serebii.net', port=443): Max retries exceeded with url: /pokearth/hoenn/3rd/route120.shtml (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb556626ef0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-ec00c1ec7f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'route120'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m'https://www.serebii.net/pokearth/hoenn/3rd/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.shtml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.serebii.net', port=443): Max retries exceeded with url: /pokearth/hoenn/3rd/route120.shtml (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb556626ef0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))"
     ]
    }
   ],
   "source": [
    "#one scrape of encounter methods\n",
    "\n",
    "loc = 'route120'\n",
    "url =  'https://www.serebii.net/pokearth/hoenn/3rd/' + str(loc) + '.shtml'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "method_list = ['grass', 'surf', 'fish', 'rocksmash', 'interact', 'gift']\n",
    "anchortab = soup.find_all('table', attrs={'class':'anctab'})\n",
    "anchortab = anchortab[1]\n",
    "anchors = anchortab.find_all('td', attrs = {'class' : method_list})\n",
    "method = []\n",
    "for anchor in anchors:\n",
    "    method.append(anchor.text.strip())\n",
    "    \n",
    "if loc == 'route120':\n",
    "    method.append('Interaction')\n",
    "\n",
    "tables = soup.find_all('table', attrs = {'class' : 'dextable'})\n",
    "\n",
    "if 'Gift Pokmon' in method:\n",
    "    method.remove('Gift Pokmon')\n",
    "    x = len(tables)\n",
    "    for n in range(x):\n",
    "        if 'Gift' in tables[x - n - 1].text:\n",
    "            tables.remove(tables[x - n - 1])\n",
    "\n",
    "encounters = []\n",
    "for table in tables:\n",
    "    tags_encounters = table.find_all('td', attrs = {'class' : 'name'})\n",
    "    encounter_by_method = []\n",
    "    for name in tags_encounters:\n",
    "        encounter_by_method.append(name.text.strip().lower())\n",
    "    encounters.append(encounter_by_method)\n",
    "\n",
    "encounter_levels = []\n",
    "for table in tables:\n",
    "    tags_levels = table.find_all('td', attrs = {'class' : 'level'})\n",
    "    levels_by_method = []\n",
    "    for level in tags_levels:\n",
    "        levels_by_method.append(int(level.text.strip()))\n",
    "    encounter_levels.append(levels_by_method)\n",
    "\n",
    "max_levels = []\n",
    "for n in range(len(encounter_levels)):\n",
    "    max_levels_by_method = []\n",
    "    for i in range(len(encounter_levels[n])):\n",
    "        if encounter_levels[n][i] == 0:\n",
    "            continue\n",
    "        if i % 2 != 0:\n",
    "            max_levels_by_method.append(encounter_levels[n][i])\n",
    "        else:\n",
    "            continue\n",
    "    max_levels.append(max_levels_by_method)\n",
    "\n",
    "\"\"\"\n",
    "for m in range(len(encounters)):\n",
    "   for x in range(len(encounters[m])):\n",
    "        cursor.execute(\"INSERT INTO WILDS (LOCATION, ENCOUNTER_ID, METHOD, NAME, LV) \\\n",
    "                        VALUES('\"+str(loc)+\"',\" \\\n",
    "                                 +str(x)+\",'\" \\\n",
    "                                 +str(method[m])+\"','\" \\\n",
    "                                 +str(encounters[m][x])+\"',\" \\\n",
    "                                 +str(max_levels[m][x])+\")\");\n",
    "                                 \n",
    "conn.commit()\n",
    "\"\"\"\n",
    "\n",
    "print(anchortab)\n",
    "print(method)\n",
    "print(encounters)\n",
    "print(max_levels)\n",
    "print(len(method) == len(encounters))\n",
    "print(len(method) == len(max_levels))\n",
    "print(len(encounters) == len(max_levels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T22:38:33.137186Z",
     "start_time": "2019-08-31T22:36:38.069446Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in range(len(locations)):\n",
    "    url =  'https://www.serebii.net/pokearth/hoenn/3rd/' + str(locations[l]) + '.shtml'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    method_list = ['grass', 'surf', 'fish', 'rocksmash', 'interact', 'gift']\n",
    "    anchortab = soup.find_all('table', attrs={'class':'anctab'})\n",
    "    anchortab = anchortab[1]\n",
    "    anchors = anchortab.find_all('td', attrs = {'class' : method_list})\n",
    "    method = []\n",
    "    for anchor in anchors:\n",
    "        method.append(anchor.text.strip().lower())\n",
    "\n",
    "    tables = soup.find_all('table', attrs = {'class' : 'dextable'})\n",
    "\n",
    "    if 'gift pokmon' in method:\n",
    "        method.remove('gift pokmon')\n",
    "        x = len(tables)\n",
    "        for n in range(x):\n",
    "            if 'Gift' in tables[x - n - 1].text:\n",
    "                tables.remove(tables[x - n - 1])\n",
    "\n",
    "    encounters = []\n",
    "    for table in tables:\n",
    "        tags_encounters = table.find_all('td', attrs = {'class' : 'name'})\n",
    "        encounter_by_method = []\n",
    "        for name in tags_encounters:\n",
    "            encounter_by_method.append(name.text.strip().lower())\n",
    "        encounters.append(encounter_by_method)\n",
    "\n",
    "    encounter_levels = []\n",
    "    for table in tables:\n",
    "        tags_levels = table.find_all('td', attrs = {'class' : 'level'})\n",
    "        levels_by_method = []\n",
    "        for level in tags_levels:\n",
    "            levels_by_method.append(int(level.text.strip()))\n",
    "        encounter_levels.append(levels_by_method)\n",
    "\n",
    "    max_levels = []\n",
    "    for n in range(len(encounter_levels)):\n",
    "        max_levels_by_method = []\n",
    "        for i in range(len(encounter_levels[n])):\n",
    "            if encounter_levels[n][i] == 0:\n",
    "                continue\n",
    "            if i % 2 != 0:\n",
    "                max_levels_by_method.append(encounter_levels[n][i])\n",
    "            else:\n",
    "                continue\n",
    "        max_levels.append(max_levels_by_method)\n",
    "    ID = 0\n",
    "    for m in range(len(encounters)): #number of encounter tables in route\n",
    "        for x in range(len(encounters[m])): #number of encounters in table\n",
    "            cursor.execute(\"INSERT INTO WILDS (LOCATION, ENCOUNTER_ID, METHOD, NAME, LV) \\\n",
    "                            VALUES('\"+str(locations[l])+\"',\" \\\n",
    "                                     +str(ID)+\",'\" \\\n",
    "                                     +str(method[m])+\"','\" \\\n",
    "                                     +str(encounters[m][x])+\"',\" \\\n",
    "                                     +str(max_levels[m][x])+\")\");\n",
    "            ID += 1\n",
    "            conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T22:38:36.503832Z",
     "start_time": "2019-08-31T22:38:36.222115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#renaming method values\n",
    "cursor.execute(\"UPDATE WILDS \\\n",
    "               SET METHOD = 'walk' \\\n",
    "               WHERE METHOD = 'standard walking';\")\n",
    "cursor.execute(\"UPDATE WILDS \\\n",
    "               SET METHOD = 'surf' \\\n",
    "               WHERE METHOD = 'standard surfing';\")\n",
    "cursor.execute(\"UPDATE WILDS \\\n",
    "               SET METHOD = 'dive' \\\n",
    "               WHERE METHOD = 'underwater';\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Wilds - Encounter Data of Multilevel Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T04:46:24.354114Z",
     "start_time": "2019-09-01T04:46:24.349426Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['route111', 'route119', 'caveoforigin', 'dewfordtown', 'evergrandecity', 'granitecave', 'meteorfalls', 'mossdeepcity', 'mt.pyre', 'newmauville', 'petalburgcity', 'safarizone', 'seafloorcavern', 'shoalcave', 'slateportcity', 'sootopoliscity', 'victoryroad']\n"
     ]
    }
   ],
   "source": [
    "print(multi)\n",
    "\"\"\"\n",
    "need manual entry\n",
    "skypillar - majority of floors are junk and don't have unique identifiers.\n",
    "abandonedship - all but one floor is junk. max_level can't be scraped.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T05:33:15.565074Z",
     "start_time": "2019-09-01T05:33:13.684554Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entrance walk', 'entrance surf', 'entrance old rod', 'entrance good rod', 'entrance super rod', 'room6 surf', 'room6 old rod', 'room6 good rod', 'room6 super rod', 'room7 surf', 'room7 old rod', 'room7 good rod', 'room7 super rod']\n",
      "[['zubat', 'golbat'], ['tentacool', 'zubat', 'golbat'], ['magikarp', 'tentacool'], ['magikarp', 'tentacool', 'wailmer'], ['wailmer'], ['tentacool', 'zubat', 'golbat'], ['magikarp', 'tentacool'], ['magikarp', 'tentacool', 'wailmer'], ['wailmer'], ['tentacool', 'zubat', 'golbat'], ['magikarp', 'tentacool'], ['magikarp', 'tentacool', 'wailmer'], ['wailmer']]\n",
      "[[35, 36], [35, 35, 35], [10, 10], [30, 30, 30], [45], [35, 35, 35], [10, 10], [30, 30, 30], [45], [35, 35, 35], [10, 10], [30, 30, 30], [45]]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#single multi-floor scrape\n",
    "\n",
    "loc = \"seafloorcavern\"\n",
    "url =  'https://www.serebii.net/pokearth/hoenn/3rd/' + str(loc) + '.shtml'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "anchortab = soup.find_all('table', attrs={'class':'anctab'})\n",
    "anchortab = anchortab[1]\n",
    "\n",
    "#where it deviates from main - if anchortab[1] contains 'Area Anchor'\n",
    "#fetch list of floors and filter junk floors\n",
    "anchors = anchortab.find_all('td', attrs = {'class' : 'pkmn'})\n",
    "floor = []\n",
    "for anchor in anchors:\n",
    "    floor.append(anchor.text.strip().lower())\n",
    "floor = list(filter(None, floor))\n",
    "null_anchors = ['gym', 'museum', 'pokemon league',\n",
    "                'space centre', 'winstrate house',\n",
    "                'underwaterentrance', 'room1', 'room2',\n",
    "                'room3', 'room4', 'room5', 'room8', 'room10']\n",
    "for anchor in null_anchors:\n",
    "    if anchor in floor:\n",
    "        floor.remove(anchor)\n",
    "\n",
    "#fetch encounter anchors by floor, and filter junk anchors\n",
    "anchors_by_floor = soup.find_all('table', attrs={'class':'anctab'})[2:]\n",
    "x = len(anchors_by_floor)\n",
    "for n in range(x):\n",
    "    if 'AnchorsRuby/SapphireEmerald' in anchors_by_floor[x - n - 1].text:\n",
    "        anchors_by_floor.remove(anchors_by_floor[x - n - 1])\n",
    "    \n",
    "#fetch encounter methods iterating such that they include floor\n",
    "method_list = ['grass', 'surf', 'fish', 'rocksmash', 'interact', 'gift']\n",
    "floor_iter = 0\n",
    "method = []\n",
    "for anchors in anchors_by_floor:\n",
    "    anchors = anchors.find_all('td', attrs = {'class' : method_list})\n",
    "    if loc == 'route111':\n",
    "        method.append('rock smash')\n",
    "    for anchor in anchors:\n",
    "        method.append(floor[floor_iter]+\" \"+anchor.text.strip().lower())\n",
    "    floor_iter += 1\n",
    "    \n",
    "if loc == 'route111':\n",
    "    method.remove(method[6])\n",
    "    \n",
    "#standardize method naming convention\n",
    "method_proper = []\n",
    "for s in method:\n",
    "    s = s.replace('standard walking', 'walk')\n",
    "    s = s.replace('standard surfing', 'surf')\n",
    "    s = s.replace('underwater', 'dive')\n",
    "    s = s.replace('main area', '')\n",
    "    method_proper.append(s.strip().lower())\n",
    "method = method_proper\n",
    "\n",
    "\n",
    "#fetch names, levels from encounter table as usual\n",
    "tables = soup.find_all('table', attrs = {'class' : 'dextable'})\n",
    "encounters = []\n",
    "for table in tables:\n",
    "    tags_encounters = table.find_all('td', attrs = {'class' : 'name'})\n",
    "    encounter_by_method = []\n",
    "    for name in tags_encounters:\n",
    "        encounter_by_method.append(name.text.strip().lower())\n",
    "    encounters.append(encounter_by_method)\n",
    "\n",
    "encounter_levels = []\n",
    "for table in tables:\n",
    "    tags_levels = table.find_all('td', attrs = {'class' : 'level'})\n",
    "    levels_by_method = []\n",
    "    for level in tags_levels:\n",
    "        levels_by_method.append(int(level.text.strip()))\n",
    "    encounter_levels.append(levels_by_method)\n",
    "\n",
    "max_levels = []\n",
    "for n in range(len(encounter_levels)):\n",
    "    max_levels_by_method = []\n",
    "    for i in range(len(encounter_levels[n])):\n",
    "        if encounter_levels[n][i] == 0:\n",
    "            continue\n",
    "        if i % 2 != 0:\n",
    "            max_levels_by_method.append(encounter_levels[n][i])\n",
    "        else:\n",
    "            continue\n",
    "    max_levels.append(max_levels_by_method)\n",
    "    \n",
    "if 'gift pokmon' in method or 'weather institute gift pokmon' in method:\n",
    "    method.remove(method[-1])\n",
    "    encounters = encounters[:-2]\n",
    "    max_levels = max_levels[:-2]\n",
    "    \n",
    "if loc == 'caveoforigin':\n",
    "    method = method[:-4]\n",
    "    \n",
    "print(method)\n",
    "print(encounters)\n",
    "print(max_levels)\n",
    "print(len(method) == len(encounters))\n",
    "print(len(method) == len(max_levels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
